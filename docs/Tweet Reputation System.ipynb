{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "  <h1>Real-Time Users' Reputation Analysis</h1>\n",
    "\n",
    "<img src=\"../images/reputation_0.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<h1>About me</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Marco Cavalli<br>\n",
    "X81000445<br>\n",
    "Student attending Computer Science at University of Catania.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Introduction</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Nowadays social networks are so much popular that we probably can't think that we can live without using them. They influence our live in different ways:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Social life"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Work/Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Business"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "More and more now we all are figuring out that we need to get a good reputation in this new virtual world. Not only this is true for a normal person, but it becomes a real deal for whoever runs a business."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1>Why should business care of its own virtual reputation?</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"../images/meme_0.jpeg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"../images/reputation_1.jpeg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1>Yeah, i see, but how do i get a good reputation?</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "That's the real deal. We can't know what makes you more popular, but we can surely figure out what we should avoid if we want to build up a good reputation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"../images/meme_1.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1>A possible solution...</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can't read the future, but we can read big data! We could indeed plan to study all the data generated by users on a social network about us. If we could do that, we could understand better what helps to build up a good reputation in real-time.\n",
    "\n",
    "<img src=\"../images/meme_3.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1>...thinking of which...</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The software we are going to illustrate is all about this: to retrieve datas an user and to quantify the user's reputation so we could tell if it's good or bad, by studying the reactions of the followers on a social network.\n",
    "\n",
    "You will be able to understand what made you raise up your reputation and what pushed all your followers away just by reading the output of this software."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "So what are you waiting for?\n",
    "\n",
    "<b>Let's start!</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Break the problem down</h1>\n",
    "\n",
    "The problem itself can be really tricky."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We want to study a social network, so we need to define which social network we want to check out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We are talking about big data. We probably can't really figure out how much big is the data users are generating each second using a social network. We do need really badly a system which can handle this hella big quantity of informations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Then we want to define a way to understand when a data generated on a social network could be seen as something which helps the user to get a better reputation or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Lastly we need a way to display easily and in a simple way all of this data to the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1>Which social network?</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Our choice is not really limited, but surely we want to choose the one which would allow us to study its data without much hassles. We need to keep in mind that datas from social networks are money and they probably don't want to give it away so easily and for free."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "That's why we will go for Twitter.\n",
    "\n",
    "<img src=\"../images/twitter_icon.png\" height=\"128\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This is a good choice because:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- It is still quite popular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- It is the easiest to get data from"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- It is common that businesses have a Twitter account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1>When big data looks like a flume...</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To handle data from a social network we need something which can help us handle all informations, good enough so it won't stop while running for some random mistake or misuse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "There are different solutions. We will use Apache Flume and a combination of ZooKeeper/Kafka Servers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Flume will help us to link the data-source (Twitter) to Kafka."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Kafka will handle the streaming of the big ammount of data Flume will generate over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This solution will allow us to keep the system reliable without giving up on efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1>How to understand what followers think?</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "At this point, we need a system which allows us to easily understand when an information (data generated by a follower of the user on Twitter) will improve or not the user's reputation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We probably won't need to tell you why we need some Machine learning to do this job.\n",
    "\n",
    "<img src=\"../images/meme_4.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We will indeed study the text of the tweets we gather and apply some sentiment analysis algorythms on them. This will lead us to understand when that tweet is generally talking \"well\" or \"bad\" about an user/agency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1>A picture is worth a thousand words</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Data generated by social networks and Machine Learning Algorythms are surely interesting, but noone can read them if we won't model them to be easy to read.\n",
    "\n",
    "<img src=\"../images/meme_5.jpeg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "That's why we will use Spark to refine the informations we get by the source and keep only what we need. Then we will use Elastic Search and Kibana to index this data and show it in a not ambiguous way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1>A really useful map to sum all we said</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"../images/tap-progetto.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Code Snippets</h1>\n",
    "\n",
    "<img src=\"../images/meme_9.jpeg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1>A flume of words</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What do Flume and ZK/Kafka servers really do? This section will help you understand better the importance to have them.\n",
    "\n",
    "Let's just start the servers and flume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system(\"gnome-terminal -e 'bash ../bin/progettoServersStart.sh'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"gnome-terminal -e 'bash ../bin/progettoCreateTopic.sh tap'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"gnome-terminal -e 'bash ../bin/progettoFlumeStart.sh tap \\\"realDonaldTrump\\\"'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1>Scripted consumer</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We start with something we could do, but it is better not to. We could indeed use a python script to get all the data from flume.\n",
    "\n",
    "(Press CTRL+C to stop the snippet code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"gnome-terminal -e 'bash ../bin/progettoCreateConsumerScript.sh tap'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "It works, but there is a big problem: it is not distributed. It is not even multithreaded.\n",
    "\n",
    "So it will be a very bad problem when it comes to talk about efficienty and performance.\n",
    "\n",
    "Can we da better job?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1>Distributed Consumer</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's now use a different approach. We will show you how this project handle this data by trying to print the same output the previous script was trying to print.\n",
    "\n",
    "(Press CTRL+C to stop the snippet code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"gnome-terminal -e 'bash ../bin/progettoSparkSnippet.sh tap'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The result is very similar, but we have assured that the software is running in a distributed way: that's possibile because Spark is a distributed solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1>What to pick?</h1>\n",
    "\n",
    "<img src=\"../images/meme_10.jpeg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "When it comes to efficienty and performance, the distributed way is the only path we should choose. It would probably work fine with the script consumer too, but when the data load is too big you would probably lose data on the road, and this is not something we really want to happen!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1>Tell me your sentiment about it</h1>\n",
    "\n",
    "Let's jump onto the sentiment analysis topic. \n",
    "\n",
    "This is a very important part of the whole software so it is worth watch it closely.\n",
    "\n",
    "We have provided two algorithms:\n",
    "- The first uses Vader for english tweets\n",
    "- The second uses SparkMLib for italian tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1>Vader</h1>\n",
    "\n",
    "<img src=\"../images/meme_11.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Vader is a model used to perform sentiment analysis. It can tell the polarity (positive, negative) of a text in a very precise way. It follows just 5 rules and uses a dictionary of terms updated by normal users.\n",
    "\n",
    "We now see an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to /home/mc/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment of 'I really hate eating vegetables!' is: negative\n",
      "Score: -0.6468\n"
     ]
    }
   ],
   "source": [
    "text = \"I really hate eating vegetables!\"\n",
    "polarity = sid.polarity_scores(text)['compound']\n",
    "sentiment = \"positive\" if polarity > 0.1 else (\"negative\" if polarity < 0.1 else \"neutral\")\n",
    "\n",
    "print(\"Sentiment of '{}' is: {}\\nScore: {}\".format(text, sentiment, polarity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "As you can see, it is not really that bad and it really gets accurate previsions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1>Spark MLib</h1>\n",
    "\n",
    "Let's see now some snippets about this part. Remember this is only for italian tweets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoderEstimator, VectorAssembler\n",
    "from pyspark.ml.feature import StopWordsRemover, Word2Vec, RegexTokenizer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "import pyspark.sql.types as tp\n",
    "\n",
    "# Create Spark Context\n",
    "sc = SparkContext(appName=\"Tweet\")\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "schema = tp.StructType([\n",
    "    tp.StructField(name= 'id', dataType= tp.StringType(),  nullable= True),\n",
    "    tp.StructField(name= 'subjective',       dataType= tp.IntegerType(),  nullable= True),\n",
    "    tp.StructField(name= 'positive',       dataType= tp.IntegerType(),  nullable= True),\n",
    "    tp.StructField(name= 'negative',       dataType= tp.IntegerType(),  nullable= True),\n",
    "    tp.StructField(name= 'ironic',       dataType= tp.IntegerType(),  nullable= True),\n",
    "    tp.StructField(name= 'lpositive',       dataType= tp.IntegerType(),  nullable= True),\n",
    "    tp.StructField(name= 'lnegative',       dataType= tp.IntegerType(),  nullable= True),\n",
    "    tp.StructField(name= 'top',       dataType= tp.IntegerType(),  nullable= True),\n",
    "    tp.StructField(name= 'tweet',       dataType= tp.StringType(),   nullable= True)\n",
    "])\n",
    "\n",
    "sc.setLogLevel(\"WARN\")\n",
    "\n",
    "# read the dataset  \n",
    "training_set = spark.read.csv('../spark/dataset/training_set_sentipolc16.csv',\n",
    "                         schema=schema,\n",
    "                         header=True,\n",
    "                         sep=',')\n",
    "\n",
    "# define stage 1: tokenize the tweet text    \n",
    "stage_1 = RegexTokenizer(inputCol= 'tweet' , outputCol= 'tokens', pattern= '\\\\W')\n",
    "# define stage 2: remove the stop words\n",
    "stage_2 = StopWordsRemover(inputCol= 'tokens', outputCol= 'filtered_words')\n",
    "# define stage 3: create a word vector of the size 100\n",
    "stage_3 = Word2Vec(inputCol= 'filtered_words', outputCol= 'vector', vectorSize= 100)\n",
    "# define stage 4: Logistic Regression Model\n",
    "model = LogisticRegression(featuresCol= 'vector', labelCol= 'positive')\n",
    "# setup the pipeline\n",
    "pipeline = Pipeline(stages= [stage_1, stage_2, stage_3, model])\n",
    "\n",
    "# fit the pipeline model with the training data\n",
    "pipelineFit = pipeline.fit(training_set)\n",
    "\n",
    "modelSummary=pipelineFit.stages[-1].summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "| id|               tweet|              tokens|      filtered_words|              vector|       rawPrediction|         probability|prediction|\n",
      "+---+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|  0|Non ti verrò a vo...|[non, ti, verr, a...|[non, ti, verr, v...|[-0.0481821253585...|[0.58488621851997...|[0.64219094847465...|       0.0|\n",
      "+---+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define Training Set Structure\n",
    "textSchema = tp.StructType([\n",
    "    tp.StructField(name= 'id', dataType= tp.LongType(),  nullable= True),\n",
    "    tp.StructField(name= 'tweet', dataType= tp.StringType(),  nullable= True)\n",
    "])\n",
    "\n",
    "text = Row([0,\"Non ti verrò a votare mai più!\"])\n",
    "wordsDataFrame = spark.createDataFrame(text, schema=textSchema)\n",
    "# transform the data using the pipeline and get the predicted sentiment\n",
    "data=pipelineFit.transform(wordsDataFrame)\n",
    "data.show(truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#Once you finish run\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Working Demo</h1>\n",
    "\n",
    "<img src=\"../images/meme_6.jpeg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1>Initial Setup</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To run all the software you must have <b>Docker</b> installed on your machine. You can surely install all the softwares one by one locally on your machine, but with docker it is way easier both to getting started and to change/fix stuff.\n",
    "\n",
    "You have no restriction about OS, but surely UNIX machines will have way easier life to get Docker running. You can still use Windows using WSL 2.\n",
    "\n",
    "You will need around <b>5/7 GB</b> to install all the stuff, but consider to have at least 10/15 GB in total because you will need space to store all the tweets you will gather using this software.\n",
    "\n",
    "Lastly you need Twitter dev keys to scrap tweets. You can get them by sign in at this website: https://developer.twitter.com/en. Once you got them you will have to modify the file <a href=\"https://github.com/Mirkesx/tap-progetto/blob/master/flume/conf/twitterKafka.conf\">twitterKafka.conf</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1>First Step</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We need to turn on both the Elastic Search/Kibana environment and the ZooKeeper/Kafka servers. To do so you just have to run this code below.\n",
    "\n",
    "After a little while yuo can check all is operating by going to the <a href=\"http://localhost:5601\">Kibana Client</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon   2.56kB\r",
      "\r\n",
      "Step 1/3 : FROM docker.elastic.co/elasticsearch/elasticsearch:7.7.0\n",
      " ---> 7ec4f35ab452\n",
      "Step 2/3 : MAINTAINER Salvo Nicotra\n",
      " ---> Using cache\n",
      " ---> 2ca07327979b\n",
      "Step 3/3 : ADD elastic.sh /\n",
      " ---> Using cache\n",
      " ---> c277f98024c9\n",
      "Successfully built c277f98024c9\n",
      "Successfully tagged tap:elasticsearch\n",
      "fbf7d53f4720839eb95f38fefcd7da826f620444471ebe7e983f79573dae66c6\n",
      "Sending build context to Docker daemon  3.072kB\r",
      "\r\n",
      "Step 1/3 : FROM  docker.elastic.co/kibana/kibana:7.7.0\n",
      " ---> eadc7b3d59dd\n",
      "Step 2/3 : MAINTAINER Salvo Nicotra\n",
      " ---> Using cache\n",
      " ---> 13a978986b30\n",
      "Step 3/3 : ADD kibana.yml /usr/share/kibana/config\n",
      " ---> Using cache\n",
      " ---> 01c96f01fe85\n",
      "Successfully built 01c96f01fe85\n",
      "Successfully tagged tap:kibana\n",
      "84e5bc49373436f6a1a8127d005527747dcabd56d96456019c462c1343cdc01c\n",
      "kafkaZK\n",
      "kafkaZK\n",
      "Sending build context to Docker daemon  62.38MB\r",
      "\r\n",
      "Step 1/11 : FROM openjdk:8-jre-alpine\n",
      " ---> f7a292bbb70c\n",
      "Step 2/11 : LABEL maintainer=\"Salvo Nicotra\"\n",
      " ---> Using cache\n",
      " ---> 6863e2590cc2\n",
      "Step 3/11 : ENV PATH /opt/kafka/bin:$PATH\n",
      " ---> Using cache\n",
      " ---> 29831ea575bc\n",
      "Step 4/11 : ENV KAFKA_DIR \"/opt/kafka\"\n",
      " ---> Using cache\n",
      " ---> 604e68798bc9\n",
      "Step 5/11 : ARG KAFKA_VERSION=\"2.12-2.4.1\"\n",
      " ---> Using cache\n",
      " ---> 4aba6e06c19d\n",
      "Step 6/11 : RUN apk update && apk add --no-cache bash gcompat\n",
      " ---> Using cache\n",
      " ---> 06854bc9a245\n",
      "Step 7/11 : ADD setup/kafka_${KAFKA_VERSION}.tgz /opt\n",
      " ---> Using cache\n",
      " ---> a1b0f9b68b2a\n",
      "Step 8/11 : RUN ln -s /opt/kafka_${KAFKA_VERSION} ${KAFKA_DIR}\n",
      " ---> Using cache\n",
      " ---> d3e20114400a\n",
      "Step 9/11 : ADD kafka-manager.sh ${KAFKA_DIR}/bin/kafka-manager\n",
      " ---> Using cache\n",
      " ---> 60b315e45d57\n",
      "Step 10/11 : ADD conf/* ${KAFKA_DIR}/config/\n",
      " ---> Using cache\n",
      " ---> cc64bfcfa9a5\n",
      "Step 11/11 : ENTRYPOINT [ \"kafka-manager\" ]\n",
      " ---> Using cache\n",
      " ---> b45d869a608f\n",
      "Successfully built b45d869a608f\n",
      "Successfully tagged tap:kafka\n",
      "db772903057954066d24f7694209787c5f51f9348e78ed62e3b5e0bfd15f13cd\n",
      "kafkaServer\n",
      "kafkaServer\n",
      "Sending build context to Docker daemon  62.38MB\r",
      "\r\n",
      "Step 1/11 : FROM openjdk:8-jre-alpine\n",
      " ---> f7a292bbb70c\n",
      "Step 2/11 : LABEL maintainer=\"Salvo Nicotra\"\n",
      " ---> Using cache\n",
      " ---> 6863e2590cc2\n",
      "Step 3/11 : ENV PATH /opt/kafka/bin:$PATH\n",
      " ---> Using cache\n",
      " ---> 29831ea575bc\n",
      "Step 4/11 : ENV KAFKA_DIR \"/opt/kafka\"\n",
      " ---> Using cache\n",
      " ---> 604e68798bc9\n",
      "Step 5/11 : ARG KAFKA_VERSION=\"2.12-2.4.1\"\n",
      " ---> Using cache\n",
      " ---> 4aba6e06c19d\n",
      "Step 6/11 : RUN apk update && apk add --no-cache bash gcompat\n",
      " ---> Using cache\n",
      " ---> 06854bc9a245\n",
      "Step 7/11 : ADD setup/kafka_${KAFKA_VERSION}.tgz /opt\n",
      " ---> Using cache\n",
      " ---> a1b0f9b68b2a\n",
      "Step 8/11 : RUN ln -s /opt/kafka_${KAFKA_VERSION} ${KAFKA_DIR}\n",
      " ---> Using cache\n",
      " ---> d3e20114400a\n",
      "Step 9/11 : ADD kafka-manager.sh ${KAFKA_DIR}/bin/kafka-manager\n",
      " ---> Using cache\n",
      " ---> 60b315e45d57\n",
      "Step 10/11 : ADD conf/* ${KAFKA_DIR}/config/\n",
      " ---> Using cache\n",
      " ---> cc64bfcfa9a5\n",
      "Step 11/11 : ENTRYPOINT [ \"kafka-manager\" ]\n",
      " ---> Using cache\n",
      " ---> b45d869a608f\n",
      "Successfully built b45d869a608f\n",
      "Successfully tagged tap:kafka\n",
      "43d30a6424ed46d7d0532934d69e4b572e69172fdd544270a97150118becbcb4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error response from daemon: No such container: elasticsearch\n",
      "Error: No such container: elasticsearch\n",
      "Error response from daemon: No such container: kibana\n",
      "Error: No such container: kibana\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "bash ../bin/progettoESKibanaStart.sh\n",
    "bash ../bin/progettoServersStart.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1>Second Step (Optional)</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "You now need to set a topic. What is a topic? A topic is a category or feed name to which records are published. It is used to let Kafka easily understand whom to send the informations it streams.\n",
    "\n",
    "In few words: we have to give a name to the data we are streaming. For this example it will be called \"tap\", but it is really not important which name you pick, so long you remember it (we will need it later on).\n",
    "\n",
    "This step is <b>required</b> only if it is the first time you run this software or if you deleted the kafka/zk volumes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kafkaTopic\n",
      "kafkaTopic\n",
      "Sending build context to Docker daemon  62.38MB\r",
      "\r\n",
      "Step 1/11 : FROM openjdk:8-jre-alpine\n",
      " ---> f7a292bbb70c\n",
      "Step 2/11 : LABEL maintainer=\"Salvo Nicotra\"\n",
      " ---> Using cache\n",
      " ---> 6863e2590cc2\n",
      "Step 3/11 : ENV PATH /opt/kafka/bin:$PATH\n",
      " ---> Using cache\n",
      " ---> 29831ea575bc\n",
      "Step 4/11 : ENV KAFKA_DIR \"/opt/kafka\"\n",
      " ---> Using cache\n",
      " ---> 604e68798bc9\n",
      "Step 5/11 : ARG KAFKA_VERSION=\"2.12-2.4.1\"\n",
      " ---> Using cache\n",
      " ---> 4aba6e06c19d\n",
      "Step 6/11 : RUN apk update && apk add --no-cache bash gcompat\n",
      " ---> Using cache\n",
      " ---> 06854bc9a245\n",
      "Step 7/11 : ADD setup/kafka_${KAFKA_VERSION}.tgz /opt\n",
      " ---> Using cache\n",
      " ---> a1b0f9b68b2a\n",
      "Step 8/11 : RUN ln -s /opt/kafka_${KAFKA_VERSION} ${KAFKA_DIR}\n",
      " ---> Using cache\n",
      " ---> d3e20114400a\n",
      "Step 9/11 : ADD kafka-manager.sh ${KAFKA_DIR}/bin/kafka-manager\n",
      " ---> Using cache\n",
      " ---> 60b315e45d57\n",
      "Step 10/11 : ADD conf/* ${KAFKA_DIR}/config/\n",
      " ---> Using cache\n",
      " ---> cc64bfcfa9a5\n",
      "Step 11/11 : ENTRYPOINT [ \"kafka-manager\" ]\n",
      " ---> Using cache\n",
      " ---> b45d869a608f\n",
      "Successfully built b45d869a608f\n",
      "Successfully tagged tap:kafka\n",
      "Running action create-topic (Kakfa Dir:/opt/kafka, ZK Server: localhost)\n",
      "Error while executing topic command : Topic 'tap' already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Stop\n",
      "docker stop kafkaTopic\n",
      "\n",
      "# Remove previuos container \n",
      "docker container rm kafkaTopic\n",
      "\n",
      "docker build ../kafka/ --tag tap:kafka\n",
      "docker run -e KAFKA_ACTION=create-topic \\\n",
      "            -e KAKFA_SERVER=10.0.100.23 \\\n",
      "            -e KAFKA_TOPIC=$1 \\\n",
      "            --network tap \\\n",
      "            --ip 10.0.100.24 \\\n",
      "            --name kafkaTopic \\\n",
      "            tap:kafka\n",
      "[2020-06-26 16:19:49,023] ERROR org.apache.kafka.common.errors.TopicExistsException: Topic 'tap' already exists.\n",
      " (kafka.admin.TopicCommand$)\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'\\nbash ../bin/progettoCreateTopic.sh tap\\n'' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-ac39095119fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\nbash ../bin/progettoCreateTopic.sh tap\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2360\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2361\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2362\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2363\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</home/mc/anaconda3/lib/python3.7/site-packages/decorator.py:decorator-gen-110>\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'\\nbash ../bin/progettoCreateTopic.sh tap\\n'' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "bash ../bin/progettoCreateTopic.sh tap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1>Third Step</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We have to turn on Flume to start gathering data.\n",
    "\n",
    "This command needs two parameters:\n",
    "- The topic\n",
    "- Comma-separated list of terms to search in tweets\n",
    "\n",
    "The topic will be \"tap\" (or whichever name you picked before). The list of terms will be a list of the Twitter usernames.\n",
    "\n",
    "In this example we will have realDonaldTrump and matteosalvinimi just to show you. The system can handle more users. Just remember that the more users you append to this list the more it will drain your pc resources (speaking of usage of cpus/rams and disk space)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system(\"gnome-terminal -e 'bash ../bin/progettoFlumeStart.sh tap \\\"realDonaldTrump, matteosalvinimi\\\"'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1>Fourth Step</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now we have to turn on all the Spark environment to start processing the data we gather before showing it.\n",
    "\n",
    "This command needs three parameters:\n",
    "- The topic\n",
    "- Space-separated list of usernames\n",
    "- Space-separated list of IDs\n",
    "\n",
    "This script needs to know which users we want to track. You have exactly two ways to define them:\n",
    "- By typing their Twitter usernames\n",
    "- By typing their Twitter IDs\n",
    "\n",
    "You must know that this list must be consistent with the one you gave to Flume: one mistake inside the list of usernames means that you would see anything displayed as output.\n",
    "\n",
    "It is required that you type \"\" if you want to enter an empty list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system(\"gnome-terminal -e 'bash ../bin/progettoSparkStart.sh tap \\\"realDonaldTrump, matteosalvinimi\\\" \\\"\\\"'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1>Fifth Step</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "It is now time to see the output. You must reach the <a href=\"http://localhost:5601\">Kibana Client</a>.\n",
    "\n",
    "By default, you already have an index (called twitter) and a working dashboard to display the data. You can always decide to change the dashboard or the index, but this is not the point of this demo, so i won't be talking about that now.\n",
    "\n",
    "First you have to refresh the index pattern.\n",
    "\n",
    "Then you may go to the Dashboard and start watching the data.\n",
    "\n",
    "Here you can use many filters to track specific data (such as the reputation of a single user, the % of bad tweets from users of one language and so on)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "You can even go \"back to the past\" to see previous statistics and understand better how the reputation system works.\n",
    "    \n",
    "<img src=\"../images/meme_7.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Thank you for listening</h1>\n",
    "\n",
    "<img src=\"../images/meme_8.jpg\">"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
